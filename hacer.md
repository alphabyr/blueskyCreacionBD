# Tareas Pendientes - Completar Scraping de Posts

## üìä Situaci√≥n Actual

- **14,900 perfiles** en `profiles_to_scan.json`
- **Solo 3,343 usuarios procesados** en `posts_usuarios.json` (22.4%)
- **~9,145 usuarios pendientes** de procesar (77.6%)
- **9,512 posts totales** obtenidos hasta ahora

El proceso de scraping se interrumpi√≥. El archivo `posts_usuarios.json` est√° **incompleto**.

---

## ‚úÖ Tareas para Completar Ma√±ana

### 1. Continuar el Scraping de Posts

El script `Main/main.py` tiene reanudaci√≥n autom√°tica. Solo necesitas ejecutarlo:

```bash
cd Main
python main.py
```

**IMPORTANTE**: 
- El script autom√°ticamente detectar√° los 3,343 usuarios ya procesados
- Solo procesar√° los ~9,145 usuarios faltantes
- Esto tomar√° **varias horas** (~2-3 horas con delays de 1 seg/usuario)
- Puedes interrumpir con `Ctrl+C` y reanudar√° desde donde lo dejaste

### 2. Alternativa: Solo Ejecutar la Parte de Posts

Si NO quieres regenerar perfiles (que ya tienes), crea y ejecuta este script:

**Archivo: `Main/solo_posts.py`**
```python
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from usuarios.post import BlueskyPostsFetcher

# Configurar handle y contrase√±a
# Opci√≥n 1: Variables de entorno (recomendado)
# export BSKY_HANDLE="tu_handle.bsky.social"
# export BSKY_APP_PASSWORD="tu_app_password"

# Opci√≥n 2: Hardcodeado (menos seguro)
HANDLE = None  # O "tu_handle.bsky.social"
APP_PASSWORD = None  # O "tu_app_password"

if __name__ == "__main__":
    fetcher = BlueskyPostsFetcher(
        handle=HANDLE,
        app_password=APP_PASSWORD,
        input_file='profiles_to_scan.json',
        output_file='posts_usuarios.json',
        posts_per_user_limit=25
    )
    fetcher.run()
```

Luego ejecuta:
```bash
cd Main
python solo_posts.py
```

### 3. Monitorear el Progreso

Durante la ejecuci√≥n, el script muestra:
- `Procesando X/9145: handle (did)`
- `Se obtuvieron X posts.`
- `Progreso guardado.`

Si se interrumpe, simplemente vuelve a ejecutar y continuar√° autom√°ticamente.

### 4. Verificar Completitud

Una vez termine, verifica que todo est√© completo:

```bash
cd analisis
python verificar_discrepancia.py
```

Deber√≠a mostrar:
- ‚úÖ `Usuarios en posts pero NO en profiles: 0` (o muy pocos)
- ‚úÖ Total de posts: mucho m√°s que 9,512

### 5. Regenerar JSONL con Todos los Posts

Una vez completado el scraping:

```bash
cd analisis
python convertir_posts_correctamente.py
```

Esto actualizar√° `posts_usuarios.jsonl` con TODOS los posts.

### 6. Ejecutar An√°lisis Completo

```bash
python main_analisis.py
```

Ahora deber√≠a mostrar miles de posts m√°s en el an√°lisis.

### 7. Limpieza Final

Elimina archivos temporales:

```bash
cd analisis
Remove-Item contar_posts_real.py, verificar_discrepancia.py, convertir_posts_correctamente.py, investigar_estructura.py -ErrorAction SilentlyContinue
```

### 8. Commit Final

```bash
git add .
git commit -m "Scraping completo de posts - todos los usuarios procesados"
git push
```

---

## ‚öôÔ∏è Configuraci√≥n Centralizada (NUEVO)

**Todas las configuraciones del proyecto ahora se gestionan desde `configuracion/config.yaml`**

### Par√°metros Configurables:

- **Spark**: Memoria driver/executor, nombre app, max fields
- **Rutas**: Nombres de archivos de entrada/salida
- **Scraping**: Usuarios por semilla, pool size, page limit
- **Posts**: L√≠mite de posts por usuario, delays entre requests
- **An√°lisis**: Top N resultados, filas a mostrar, truncado

### Para modificar la configuraci√≥n:

Edita `configuracion/config.yaml` y cambia los valores seg√∫n necesites:

```yaml
scraping:
  usuarios_por_semilla: 10  # Cambiar seg√∫n necesites
  pool_size: 12

posts:
  posts_por_usuario_limite: 25  # Aumentar si quieres m√°s posts
  delay_entre_requests: 1  # Aumentar si hay rate limits

spark:
  driver_memory: "8g"  # Aumentar si tienes m√°s RAM
  executor_memory: "8g"
```

**No necesitas modificar ning√∫n archivo Python** - todos leen autom√°ticamente desde el YAML.

---

## üîß Configuraci√≥n de Credenciales

Si te falta configurar las credenciales para el scraping:

### Opci√≥n A: Variables de Entorno (Recomendado)

**Windows PowerShell:**
```powershell
$env:BSKY_HANDLE = "tu_handle.bsky.social"
$env:BSKY_APP_PASSWORD = "tu_app_password"
```

### Opci√≥n B: Archivo .env

Crea `.env` en la ra√≠z del proyecto:
```
BSKY_HANDLE=tu_handle.bsky.social
BSKY_APP_PASSWORD=tu_app_password
```

### Opci√≥n C: Modificar main.py

En `Main/main.py` l√≠nea 125-127:
```python
if __name__ == "__main__":
    app = MainApp(
        bsky_handle="tu_handle.bsky.social",
        bsky_app_password="tu_app_password"
    )
    app.run()
```

---

## ‚ö†Ô∏è Problemas Comunes

### Rate Limit
Si ves `RateLimit exceeded`:
- El script autom√°ticamente espera 60 segundos
- D√©jalo continuar, se recuperar√° solo

### "Actor not found" / "Profile not found"
- Normal, algunos usuarios borran sus cuentas
- El script los salta autom√°ticamente
- No afecta a los dem√°s usuarios

### El script se cuelga
- Presiona `Ctrl+C` para interrumpir
- Vuelve a ejecutar, continuar√° desde donde lo dejaste

---

## üìà Estimaci√≥n de Tiempo

- **~9,145 usuarios pendientes**
- **1 segundo de delay por usuario** (para evitar rate limits)
- **Tiempo estimado**: ~2.5 horas (9145 seg = 152 min)
- Puede ser m√°s si hay rate limits o errores de red

---

## ‚úÖ Checklist Final

- [ ] Ejecutar scraping de posts faltantes (`main.py` o `solo_posts.py`)
- [ ] Verificar completitud con `verificar_discrepancia.py`
- [ ] Regenerar JSONL con `convertir_posts_correctamente.py`
- [ ] Ejecutar an√°lisis completo con `main_analisis.py`
- [ ] Verificar que el an√°lisis muestre miles de posts m√°s
- [ ] Limpiar archivos temporales
- [ ] Commit y push